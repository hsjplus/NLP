{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석(Konlpy의 Twitter와 Soynlp 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from soynlp.tokenizer import LTokenizer, MaxScoreTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_tag = Twitter()\n",
    "l_tokenizer = LTokenizer()\n",
    "max_tokenizer = MaxScoreTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 띄어쓰기가 잘 안 된 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 관련 texts\n",
    "texts = ['난파스타가 좋아요', '이렇게연속된문장은잘리지않습니다만']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['난파', '스타', '가', '좋', '아요']\n",
      "['이렇게', '연속', '된', '문장', '은', '잘리', '지', '않', '습니다만']\n"
     ]
    }
   ],
   "source": [
    "# twitter의 morphs 메소드\n",
    "for text in texts:\n",
    "    print(twitter_tag.morphs(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['난파스타가', '좋아요']\n",
      "['이렇게연속된문장은잘리지않습니다만']\n",
      "['난파스타가', '좋아요']\n",
      "['이렇게연속된문장은잘리지않습니다만']\n",
      "=> score를 부여해도 띄어쓰기가 잘 안되면 소용 없음\n"
     ]
    }
   ],
   "source": [
    "# soynlp의 l_tokenizer 메소드 \n",
    "for text in texts:\n",
    "    print(l_tokenizer.tokenize(text))\n",
    "\n",
    "# 임의의 score를 부여한 경우 (등록된 단어는 점수 우선순위에 따라 따로 token화함)\n",
    "l_tokenizer_score = LTokenizer(scores={'파스타': 1.0, '문장': 1.0})\n",
    "for text in texts:\n",
    "    print(l_tokenizer_score.tokenize(text))\n",
    "\n",
    "print('=> score를 부여해도 띄어쓰기가 잘 안되면 소용 없음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['난파스타가', '좋아요']\n",
      "['이렇게연속된문장은잘', '리지않습니다만']\n",
      "['난', '파스타', '가', '좋아요']\n",
      "['이렇게연속된', '문장', '은잘리지않습니다만']\n"
     ]
    }
   ],
   "source": [
    "# soynlp의 max_tokenizer 메소드\n",
    "for text in texts:\n",
    "    print(max_tokenizer.tokenize(text))\n",
    "\n",
    "# 임의의 score를 부여한 경우 (등록된 단어는 점수 우선순위에 따라 따로 token화함)\n",
    "max_tokenizer_score = MaxScoreTokenizer(scores={'파스타': 1.0, '파스': 0.3, '문장': 1.0})\n",
    "for text in texts:\n",
    "    print(max_tokenizer_score.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 띄어쓰기가 잘 된 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 관련 texts\n",
    "texts = ['난 파스타가 좋아요'\n",
    "        , '데이터마이닝을 공부한다'\n",
    "        , '데이터분석을 위해서 데이터마이닝을 공부한다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['난', '파스타', '가', '좋', '아요']\n",
      "['데이터마이닝', '을', '공부', '한', '다']\n",
      "['데이터', '분석', '을', '위해서', '데이터마이닝', '을', '공부', '한', '다']\n"
     ]
    }
   ],
   "source": [
    "# twitter의 morphs 메소드 \n",
    "for text in texts:\n",
    "    print(twitter_tag.morphs(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['난', '파스타가', '좋아요']\n",
      "['데이터마이닝을', '공부한다']\n",
      "['데이터분석을', '위해서', '데이터마이닝을', '공부한다']\n",
      "['난', '파스타', '가', '좋아요']\n",
      "['데이터마이닝', '을', '공부', '한다']\n",
      "['데이터', '분석을', '위해서', '데이터마이닝', '을', '공부', '한다']\n"
     ]
    }
   ],
   "source": [
    "# soynlp의 l_tokenizer 메소드 \n",
    "for text in texts:\n",
    "    print(l_tokenizer.tokenize(text))\n",
    "\n",
    "# 임의의 score를 부여한 경우 (등록된 단어는 점수 우선순위에 따라 따로 token화함)\n",
    "scores={'데이터': 0.5, '데이터마이닝':0.5, '공부': 0.5, '파스타': 0.5}\n",
    "l_tokenizer_score = LTokenizer(scores=scores)\n",
    "for text in texts:\n",
    "    print(l_tokenizer_score.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['난', '파스타가', '좋아요']\n",
      "['데이터마이닝을', '공부한다']\n",
      "['데이터분석을', '위해서', '데이터마이닝을', '공부한다']\n",
      "['난', '파스타', '가', '좋아요']\n",
      "['데이터마이닝', '을', '공부', '한다']\n",
      "['데이터', '분석을', '위해서', '데이터마이닝', '을', '공부', '한다']\n"
     ]
    }
   ],
   "source": [
    "# soynlp의 max_tokenizer 메소드\n",
    "for text in texts:\n",
    "    print(max_tokenizer.tokenize(text))\n",
    "\n",
    "# 임의의 score를 부여한 경우 (등록된 단어는 점수 우선순위에 따라 따로 token화함)\n",
    "max_tokenizer_score = MaxScoreTokenizer(scores=scores)\n",
    "for text in texts:\n",
    "    print(max_tokenizer_score.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기능 분석 관련 소견 및 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 속도와 tolerance 기능을 제외 한다면, soynlp의 LTokenizer의 필요성을 모르겠음 (MaxScoreTokenizer로 모두 대체 가능)\n",
    "- 다루지 않은 것: soynlp의 RegexTokenizer, twitter의 nouns와 pos 메소드 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/lovit/soynlp/blob/master/tutorials/tokenizer_usage.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
